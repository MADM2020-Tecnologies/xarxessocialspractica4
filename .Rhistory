error.ridge
error.mss
x=model.matrix(Apps~.,datos)[,-1]
#Variable independiente
y=Apps
y.test=y[test]
# grid = rango de valores para el parametro de penalización
grid=10^seq(10,-2, length =100)
#Ridge impone alpha = 0
cv.ridge=cv.glmnet(x[train ,],y[train],alpha=0,lambda=grid)
plot(cv.ridge)
mejorlambda=cv.ridge$lambda.min
mejorlambda
ridge.mod=glmnet(x[train ,],y[train],alpha=0,lambda=grid)
ridge.pred=predict(ridge.mod,s=mejorlambda ,newx=x[test ,])
mean((ridge.pred-y.test)^2)
error.ridge <- mean((ridge.pred-datos.test[, "Apps"] )^2)
error.ridge
set.seed(111)
#install.packages("glmnet")
library(glmnet)
#todas las variables explicativas.
x=model.matrix(Apps~.,datos)[,-1]
#Variable independiente
y=Apps
y.test=y[test]
# grid = rango de valores para el parametro de penalización
grid=10^seq(10,-2, length =100)
#Ridge impone alpha = 0
cv.ridge=cv.glmnet(x[train ,],y[train],alpha=0,lambda=grid)
plot(cv.ridge)
mejorlambda=cv.ridge$lambda.min
mejorlambda
ridge.mod=glmnet(x[train ,],y[train],alpha=0,lambda=grid)
ridge.pred=predict(ridge.mod,s=mejorlambda ,newx=x[test ,])
mean((ridge.pred-y.test)^2)
error.ridge <- mean((ridge.pred-datos.test[, "Apps"] )^2)
error.ridge
plot(ridge.mod)
View(data4)
rm(list=ls())
cat("\014") ## limpia la pantalla del R
## Define el directorio de trabajo
setwd("C:/Users/usuario/Dropbox/CURSOS/11633 - Econometr???a para Datos Masivos/Bloque 2_M???todos de Reducci???n/Tema7_Clase Pr???ctica")
## Carga los datos
library(ISLR)
set.seed(111)
attach(College)
## (a) ##
Private2=rep(0,nrow(College))
Private2[College$Private == "Yes"]= 1
datos <- data.frame(College)
datos$Private = Private2
## (b) ##
set.seed(111)
train.size = dim(datos)[1] / 2
train = sample(1:dim(datos)[1], train.size)
test = -train
datos.train = datos[train, ]
datos.test = datos[test, ]
## (c) ##
lm.fit = lm(Apps~., data=datos.train)
lm.pred = predict(lm.fit, newdata = datos.test)
mean((datos.test[, "Apps"] - lm.pred)^2)
error.mco <- mean((datos.test[, "Apps"] - lm.pred)^2)
error.mco
## (d) ##
install.packages("leaps")
library(leaps)
nvariables <- as.numeric(dim(datos)[2] -1)
regfit.full=regsubsets(Apps~.,data= datos[train,],nvmax=nvariables)
predict.regsubsets=function(object,newdata,id,...){
form=as.formula(object$call[[2]])
mat=model.matrix(form,newdata)
coefi=coef(object,id=id)
xvars=names(coefi)
mat[,xvars]%*%coefi
}
k = 10
set.seed(111)
folds=sample(1:k,nrow(datos.train),replace=TRUE)
folds
table(folds)
cv.errors=matrix(NA,k,nvariables, dimnames =list(NULL , paste(1:nvariables)))
for(j in 1:k){
best.fit=regsubsets(Apps~.,data=datos.train[folds!=j,],
nvmax=nvariables)
for(i in 1:nvariables){
pred=predict.regsubsets(best.fit,datos.train[folds==j,],id=i)
cv.errors[j,i]=mean( (datos.train$Apps[folds==j]-pred)^2)
}
}
rmse.cv=sqrt(apply(cv.errors,2,mean))
rmse.cv
which.min(rmse.cv)
plot(rmse.cv,pch=19,type="b")
reg.best=regsubsets (Apps~.,data=datos.train , nvmax=nvariables)
coef(reg.best ,which.min(rmse.cv))
fit.final <- lm(Apps ~ Accept + Top10perc, data = datos.train)
summary(fit.final)
regfit.full=regsubsets(Apps~.,data= datos[train,],nvmax=nvariables)
lm.pred = predict.regsubsets(regfit.full, newdata = datos.test, id=which.min(rmse.cv))
error.mss <- mean((datos.test[, "Apps"] - lm.pred)^2)
error.mss
# Regla del "codo" de una DT del error de VC:
dt.cv = sd(rmse.cv)
which.max(rmse.cv - dt.cv <= min(rmse.cv))
## (e) ##
k = 10
set.seed(111)
folds=sample(1:k,nrow(datos.train),replace=TRUE)
folds
table(folds)
cv.errors=matrix(NA,k,nvariables, dimnames =list(NULL , paste(1:nvariables)))
for(j in 1:k){
#Implementamos Forward selection
best.fit=regsubsets(Apps~.,data=datos.train[folds!=j,],
nvmax=nvariables, method = "forward")
for(i in 1:nvariables){
pred=predict.regsubsets(best.fit,datos.train[folds==j,],id=i)
cv.errors[j,i]=mean( (datos.train$Apps[folds==j]-pred)^2)
}
}
rmse.cv=sqrt(apply(cv.errors,2,mean))
rmse.cv
which.min(rmse.cv)
plot(rmse.cv,pch=19,type="b")
regfit.f=regsubsets(Apps~.,data=datos.train , nvmax=nvariables, method = "forward")
coef(regfit.f,which.min(rmse.cv))
fit.final <- lm(Apps ~ Accept + Top10perc, data = datos.train)
summary(fit.final)
regfit.f=regsubsets(Apps~.,data= datos[train,],nvmax=nvariables, method = "forward")
lm.pred = predict.regsubsets(regfit.f, newdata = datos.test, id=which.min(rmse.cv))
error.msha <- mean((datos.test[, "Apps"] - lm.pred)^2)
error.msha
# Regla del "codo" de una DT del error de VC:
dt.cv = sd(rmse.cv)
dt = which.max(rmse.cv - dt.cv <= min(rmse.cv))
dt
lm.pred = predict.regsubsets(regfit.full, newdata = datos.test, id=5)
error.msha.codo <- mean((datos.test[, "Apps"] - lm.pred)^2)
error.msha.codo
## (f) ##
k = 5
set.seed(111)
folds=sample(1:k,nrow(datos.train),replace=TRUE)
folds
table(folds)
cv.errors=matrix(NA,k,nvariables, dimnames =list(NULL , paste(1:nvariables)))
for(j in 1:k){
#Implementamos Forward selection
best.fit=regsubsets(Apps~.,data=datos.train[folds!=j,],
nvmax=nvariables, method = "forward")
for(i in 1:nvariables){
pred=predict.regsubsets(best.fit,datos.train[folds==j,],id=i)
cv.errors[j,i]=mean( (datos.train$Apps[folds==j]-pred)^2)
}
}
rmse.cv=sqrt(apply(cv.errors,2,mean))
rmse.cv
which.min(rmse.cv)
plot(rmse.cv,pch=19,type="b")
regfit.f=regsubsets(Apps~.,data=datos.train , nvmax=nvariables, method = "forward")
coef(regfit.f,which.min(rmse.cv))
fit.final <- lm(Apps ~ Accept + Top10perc, data = datos.train)
summary(fit.final)
regfit.f=regsubsets(Apps~.,data= datos[train,],nvmax=nvariables, method = "forward")
lm.pred = predict.regsubsets(regfit.f, newdata = datos.test, id=which.min(rmse.cv))
error.msha.VC5 <- mean((datos.test[, "Apps"] - lm.pred)^2)
error.msha.VC5
# Regla del "codo" de una DT del error de VC:
dt.cv = sd(rmse.cv)
dt = which.max(rmse.cv - dt.cv <= min(rmse.cv))
dt
lm.pred = predict.regsubsets(regfit.full, newdata = datos.test, id=5)
error.msha.codo <- mean((datos.test[, "Apps"] - lm.pred)^2)
error.msha.codo
## (g) ##
A <- matrix( c(error.mco, error.mss, error.msha, error.mss, error.msha.VC5),
nrow = 1, ncol = 5)
dimnames(A) <- list("RMSE", c("MCO", "MSS", "MSHA", "MSS.VC5", "MSHA.VC5"))
A
which.min(A)
## (h) ##
###### (2) ############### LASSO
## (a) ###
set.seed(111)
#install.packages("glmnet")
library(glmnet)
#todas las variables explicativas.
x=model.matrix(Apps~.,datos)[,-1]
#Variable independiente
y=Apps
y.test=y[test]
# grid = rango de valores para el parametro de penalización
grid=10^seq(10,-2, length =100)
#Ridge impone alpha = 0
cv.ridge = cv.glmnet(x[train ,],y[train],alpha=0,lambda=grid)
plot(cv.ridge)
mejorlambda=cv.ridge$lambda.min
mejorlambda
ridge.mod=glmnet(x[train ,],y[train],alpha=0,lambda=grid)
ridge.pred=predict(ridge.mod,s=mejorlambda ,newx=x[test ,])
mean((ridge.pred-y.test)^2)
error.ridge <- mean((ridge.pred-datos.test[, "Apps"] )^2)
error.ridge
plot(ridge.mod)
# Regla del "codo" de una DT del error de VC:
lambda.codo <- cv.ridge$lambda.1se
lambda.codo
ridge.pred.2=predict(ridge.mod,s=lambda.codo,newx=x[test ,])
error.ridge.2 <- mean((ridge.pred.2-datos.test[, "Apps"] )^2)
error.ridge.2
## (b) ###
set.seed(111)
cv.lasso=cv.glmnet(x[train ,],y[train],alpha=1, lambda = grid)
plot(cv.lasso)
bestlam=cv.lasso$lambda.min
bestlam
lasso.mod=glmnet(x[train ,],y[train],alpha=1,lambda=grid)
plot(lasso.mod)
lasso.pred=predict(lasso.mod,s=bestlam,newx=x[test ,])
# Regla del "codo" de una DT del error de VC:
lambda.codo.l <- cv.lasso$lambda.1se
lambda.codo.l
lasso.pred.2=predict(lasso.mod,s=lambda.codo.l,newx=x[test ,])
error.lasso.2 <- mean((lasso.pred.2-datos.test[, "Apps"] )^2)
error.lasso.2
coef(cv.lasso)   #No utilizar estos coeficientes por que no son reales. son inconsistentes.
## (c) ###
set.seed(111)
x=model.matrix(Apps~.,datos)[,-1]
y=Apps
y.test=y[test]
grid=10^seq(10,-2, length =100)
cv.ridge=cv.glmnet(x[train ,],y[train],alpha=0,lambda=grid, nfolds = 5)
plot(cv.ridge)
mejorlambda=cv.ridge$lambda.min
mejorlambda
ridge.mod=glmnet(x[train ,],y[train],alpha=0,lambda=grid)
ridge.pred=predict(ridge.mod,s=mejorlambda ,newx=x[test ,])
mean((ridge.pred-y.test)^2)
error.ridge.VC5 <- mean((ridge.pred-datos.test[, "Apps"] )^2)
error.ridge.VC5
# Regla del "codo" de una DT del error de VC:
lambda.codo <- cv.ridge$lambda.1se
lambda.codo
ridge.pred.2=predict(ridge.mod,s=lambda.codo,newx=x[test ,])
error.ridge.VC5.2 <- mean((ridge.pred.2-datos.test[, "Apps"] )^2)
error.ridge.VC5.2
## (d) ###
library(pls)
set.seed(111)
pcr.fit=pcr(Apps~., data=datos,subset=train,scale=TRUE, validation="CV")
summary(pcr.fit)
validationplot(pcr.fit,val.type="MSEP", xlab = "N???mero de Componentes Principales")
pcr.cv <- crossval(pcr.fit, segments = 10)
plot(RMSEP(pcr.cv), legendpos="topright")
summary(pcr.cv, what = "validation")
acp <- prcomp(datos[,-2]), center= T, scale = T)
acp <- prcomp(datos.train[,-2]), center= T, scale = T)
acp <- prcomp(datos.train[,-2], center= T, scale = T)
summary(acp)
## (e) ###
set.seed(111)
pls.fit=plsr(Apps~., data=datos,subset=train,scale=TRUE, validation="CV")
summary(pls.fit)
?pl
??plsr
pls.fit=plsr(Apps~., data=datos,subset=train,scale=TRUE, validation="CV")
install.packages("pls")
library(pls)
pls.fit=plsr(Apps~., data=datos,subset=train,scale=TRUE, validation="CV")
summary(pls.fit)
validationplot(pls.fit,val.type="MSEP", xlab = "N???mero de Componentes Principales")
plot(RMSEP(pls.cv), legendpos="topright")
summary(pls.cv, what = "validation")
plot(RMSEP(pls.cv), legendpos="topright")
pls.cv <- crossval(pls.fit, segments = 10)
plot(RMSEP(pls.cv), legendpos="topright")
summary(pls.cv, what = "validation")
## Utilizamos 12 componentes por el M???nimo Error de VC
pls.pred=predict(pls.fit,newdata=x[test,],ncomp=8)
error.pls <- mean((pls.pred - datos.test[, "Apps"])^2)
error.pls
## Selecciona el n???mero de componentes principales
## Regla del codo: 1 d.t.
ncomp.1.d.t. <- selectNcomp(pls.fit, method = "onesigma", plot = TRUE, validation = "CV",
segments = 10)
ncomp.1.d.t.
pls.pred.2=predict(pls.fit,newdata=x[test,],ncomp=ncomp.1.d.t.)
error.pls.codo <- mean((pls.pred.2 - datos.test[, "Apps"])^2)
error.pls.codo
## Regla de la permutaci???n: se selecciona el ncomp que nos da el min Error de VC
## Luego, se contrasta si hay una deterioraci???n del Error de VC al quitar un componente
## del Modelo de PLS, utilizando un alpha = 0.05. Este m???todo utiliza la VC LOOC
ncomp.perm <- selectNcomp(pls.fit, method = "randomization", plot = TRUE)
ncomp.perm
pls.pred.3=predict(pls.fit,newdata=x[test,],ncomp=ncomp.perm)
error.pls.perm <- mean((pls.pred.3 - datos.test[, "Apps"])^2)
error.pls.perm
### (f) ###
library(glmnet)
library(caret)
lambda.grid <- 10^seq(2,-2, length = 100)
alpha.grid <- seq(0,1, by = 0.05)
lambda.grid
alpha.grid
alpha.grid
Control <- trainControl(method = "cv", number = 10)
busca.grid <- expand.grid(alpha = alpha.grid, lambda = lambda.grid)
busca.grid
set.seed(111)
mi.entrenamiento <- train(Apps~., data = datos.train, method = "glmnet",
tuneGrid = busca.grid, trControl = Control,
tuneLength = 10,
standardize = TRUE, maxit = 1000000)
plot(mi.entrenamiento)
attributes(mi.entrenamiento)
mi.entrenamiento$bestTune
mi.entrenamiento$finalModel
mi.modelo.glmnet <- mi.entrenamiento$finalModel
coef(mi.modelo.glmnet, s = mi.entrenamiento$bestTune$lambda)
mej.modelo <- glmnet(x[train ,],y[train], alpha=mi.entrenamiento$bestTune$alpha,
lambda = mi.entrenamiento$bestTune$lambda)
coef(mej.modelo, s = mi.entrenamiento$bestTune$lambda)
cbind(coef(mej.modelo, s = mi.entrenamiento$bestTune$lambda), coef(mi.modelo.glmnet, s = mi.entrenamiento$bestTune$lambda))
lre.pred <- predict(mej.modelo,s=mi.entrenamiento$bestTune$lambda,newx=x[test ,])
### (h) ###
library(selectiveInference)
## Reestimamos el LASSO
set.seed(111)
cv.lasso=cv.glmnet(x[train ,],y[train],alpha=1, lambda = grid)
bestlam=cv.lasso$lambda.min
lasso.mod=glmnet(x[train ,],y[train],alpha=1,lambda=grid)
## Obtenemos los coeficientes dado el lambda mediante el comando "beta = coef(obj, s=lambda/n)[-1]",
## donde "obj" es el resultado de glmnet (y "[-1]" elimina el intercepto, el cual glmnet siempre pone
## en el primer componente)
n = nrow(x[train,])
## Notad que dividimos el lambda ???ptimo por "n" porque no se divide por "n" la funci???n objetivo del
## LASSO en esta package, mientras el glmnet la divide por "n"
coef(lasso.mod, s=bestlam/n, exact=TRUE, x = x[train ,], y = y[train])[-1]
beta <- coef(lasso.mod, s=bestlam/n, exact=TRUE, x = x[train ,], y = y[train])[-1]
## Calcula los p-valores e ICs para la estimaci???n del LASSO, dado un valor fijo del lambda
out <- fixedLassoInf(x[train ,],y[train],beta,bestlam)
out
### Notad que los resultados sugieren que las variables 5, 6, 7, 10, 12, 13, 14, 15 y 16 son
### no significativas al 5% de significaci???n. Vamos a quitarlas del modelo para rehacer el contraste:
x.new <- x[,-c(5,6,7,10,12,13,14,15,16)]
set.seed(111)
cv.lasso=cv.glmnet(x.new[train ,],y[train],alpha=1, lambda = grid)
bestlam=cv.lasso$lambda.min
lasso.mod=glmnet(x.new[train ,],y[train],alpha=1,lambda=grid)
beta <- coef(lasso.mod, s=bestlam/n, exact=TRUE, x = x.new[train ,], y = y[train])[-1]
out <- fixedLassoInf(x.new[train ,],y[train],beta,bestlam)
out
x.new <- x.new[, -1]
# Calcula p-valores e intervalos de confianza tras k pasos
fsfit = fs(x[train,],y[train])
out.fix = fsInf(fsfit,type="all",k=2)
out.fix
# Calcula p-valores secuenciales e intervalos de confianza
# (con el sigma estimado a partir del modelo lleno)
out.seq = fsInf(fsfit)
out.seq
### (i) ###
B <- matrix( c(error.lasso, error.ridge, error.lasso.VC5, error.ridge.VC5, error.pls,
error.pls.VC5),
nrow = 1, ncol = 6)
dimnames(B) <- list("RMSE", c("LASSO", "Ridge", "LASSO.VC5", "Ridge.VC5", "PLS",
"PLS.VC5"))
B
lambda.grid <- 10^seq(2,-2, length = 100)
alpha.grid <- seq(0,1, by = 0.05)
lambda.grid
alpha.grid
Control <- trainControl(method = "cv", number = 10)
busca.grid <- expand.grid(alpha = alpha.grid, lambda = lambda.grid)
busca.grid
set.seed(111)
mi.entrenamiento <- train(Apps~., data = datos.train, method = "glmnet",
tuneGrid = busca.grid, trControl = Control,
tuneLength = 10,
standardize = TRUE, maxit = 1000000)
plot(mi.entrenamiento)
plot(mi.entrenamiento)
attributes(mi.entrenamiento)
mi.entrenamiento$bestTune
mi.entrenamiento$finalModel
attributes(mi.entrenamiento)
mi.entrenamiento$bestTune
mi.entrenamiento$finalModel
attributes(mi.entrenamiento)
mi.entrenamiento$bestTune
mi.entrenamiento$finalModel
mi.modelo.glmnet <- mi.entrenamiento$finalModel
coef(mi.modelo.glmnet, s = mi.entrenamiento$bestTune$lambda)
mej.modelo <- glmnet(x[train ,],y[train], alpha=mi.entrenamiento$bestTune$alpha,
lambda = mi.entrenamiento$bestTune$lambda)
coef(mej.modelo, s = mi.entrenamiento$bestTune$lambda)
cbind(coef(mej.modelo, s = mi.entrenamiento$bestTune$lambda), coef(mi.modelo.glmnet, s = mi.entrenamiento$bestTune$lambda))
lre.pred <- predict(mej.modelo,s=mi.entrenamiento$bestTune$lambda,newx=x[test ,])
error.pred <- mean((lre.pred - y.test)^2)
error.pred
error.pls
error.pred
Control <- trainControl(method = "cv", number = 5)
set.seed(111)
mi.entrenamiento <- train(Apps~., data = datos.train, method = "glmnet",
tuneGrid = busca.grid, trControl = Control,
tuneLength = 5,
standardize = TRUE, maxit = 1000000)
plot(mi.entrenamiento)
attributes(mi.entrenamiento)
mi.entrenamiento$bestTune
mi.entrenamiento$finalModel
mi.modelo.glmnet <- mi.entrenamiento$finalModel
coef(mi.modelo.glmnet, s = mi.entrenamiento$bestTune$lambda)
mej.modelo <- glmnet(x[train ,],y[train], alpha=mi.entrenamiento$bestTune$alpha,
lambda = mi.entrenamiento$bestTune$lambda)
coef(mej.modelo, s = mi.entrenamiento$bestTune$lambda)
cbind(coef(mej.modelo, s = mi.entrenamiento$bestTune$lambda), coef(mi.modelo.glmnet, s = mi.entrenamiento$bestTune$lambda))
lre.pred <- predict(mej.modelo,s=mi.entrenamiento$bestTune$lambda,newx=x[test ,])
error.pred <- mean((lre.pred - y.test)^2)
error.pred
mi.entrenamiento$finalModel
mi.entrenamiento$bestTune
mi.entrenamiento$finalModel
mi.modelo.glmnet <- mi.entrenamiento$finalModel
coef(mi.modelo.glmnet, s = mi.entrenamiento$bestTune$lambda)
mej.modelo <- glmnet(x[train ,],y[train], alpha=mi.entrenamiento$bestTune$alpha,
lambda = mi.entrenamiento$bestTune$lambda)
coef(mej.modelo, s = mi.entrenamiento$bestTune$lambda)
cbind(coef(mej.modelo, s = mi.entrenamiento$bestTune$lambda), coef(mi.modelo.glmnet, s = mi.entrenamiento$bestTune$lambda))
lre.pred <- predict(mej.modelo,s=mi.entrenamiento$bestTune$lambda,newx=x[test ,])
error.pred <- mean((lre.pred - y.test)^2)
error.pred
lre.pred.vc5 <- predict(mej.modelo,s=mi.entrenamiento$bestTune$lambda,newx=x[test ,])
error.pred.vc5 <- mean((lre.pred.vc5 - y.test)^2)
error.pred.vc5
error.pred
lambda.grid <- 10^seq(2,-2, length = 100)
alpha.grid <- seq(0,1, by = 0.05)
lambda.grid
alpha.grid
Control <- trainControl(method = "cv", number = 10)
busca.grid <- expand.grid(alpha = alpha.grid, lambda = lambda.grid)
busca.grid
set.seed(111)
mi.entrenamiento <- train(Apps~., data = datos.train, method = "glmnet",
tuneGrid = busca.grid, trControl = Control,
tuneLength = 10,
standardize = TRUE, maxit = 1000000)
plot(mi.entrenamiento)
attributes(mi.entrenamiento)
mi.entrenamiento$bestTune
mi.entrenamiento$finalModel
mi.modelo.glmnet <- mi.entrenamiento$finalModel
coef(mi.modelo.glmnet, s = mi.entrenamiento$bestTune$lambda)
mej.modelo <- glmnet(x[train ,],y[train], alpha=mi.entrenamiento$bestTune$alpha,
lambda = mi.entrenamiento$bestTune$lambda)
coef(mej.modelo, s = mi.entrenamiento$bestTune$lambda)
cbind(coef(mej.modelo, s = mi.entrenamiento$bestTune$lambda), coef(mi.modelo.glmnet, s = mi.entrenamiento$bestTune$lambda))
lre.pred <- predict(mej.modelo,s=mi.entrenamiento$bestTune$lambda,newx=x[test ,])
error.pred <- mean((lre.pred - y.test)^2)
error.pred
error.pred
error.pred.vc5
setwd("~/GitHub/xarxessocialspractica4")
G=sample_pa(1000, directed=FALSE)
library(knitr)
library(igraph)
G=sample_pa(1000, directed=FALSE)
beta = 0.1
gamma = 0.1
A = as_adjacency_matrix(G, type = "lower",
attr = NULL, edges = FALSE, names = TRUE,
sparse = F)
A
A = as_adjacency_matrix(G)
A
A = as_adjacency_matrix(G, type = "lower",
attr = NULL, edges = FALSE, names = TRUE,
sparse = F)
A
A = as_adjacency_matrix(G)
A = as_adjacency_matrix(G)
?as_adjacency_matrix
A = as_adjacency_matrix(G, type = "lower",
attr = NULL, edges = FALSE, names = TRUE)
A
A = as_adjacency_matrix(G, type = "lower",
attr = NULL, edges = FALSE, names = TRUE,
sparse = F)
A
A = as_adjacency_matrix(G, undirected = T)
?as_adjacency_matrix
A = as_adjacency_matrix(G)
A
E = eigen(A)
E$vectors
A %*% (E$vectors[,1])
E$values[1]*(E$vectors[,1])
View(A)
View(E)
set.seed(1)
G= sample_pa(1000, directed=FALSE)
A = as_adjacency_matrix(G)
E = eigen(A)
t = 0.1
beta = 0.1
gamma = 0.1
